{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99036adb-091a-4318-afd0-0b95ebf66a7d",
   "metadata": {},
   "source": [
    "# **Day 52: Cross-Validation Techniques** ðŸ”„\r\n",
    "\r\n",
    "Cross-validation is a crucial technique in machine learning to evaluate the generalization performance of models. It ensures robust results, reduces overfitting, and provides an unbiased assessment of a modelâ€™s performance.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## **What is Cross-Validation?**\r\n",
    "- **Cross-validation** is a statistical method to split a dataset into **training** and **testing** subsets multiple times.  \r\n",
    "- It evaluates the model on different subsets of data, improving the reliability of the performance metrics.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## **Why is Cross-Validation Important?**\r\n",
    "- **Reduces Overfitting**: Ensures the model is tested on unseen data multiple times, preventing memorization of the training data.  \r\n",
    "- **Improves Generalization**: Provides a better estimate of how the model will perform on new, unseen data.  \r\n",
    "- **Ensures Robustness**: Validates that the model has learned patterns that generalize well beyond the training data.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## **Types of Cross-Validation Techniques**\r\n",
    "\r\n",
    "### **1. K-Fold Cross-Validation**  \r\n",
    "- The dataset is split into **k subsets (folds)**.  \r\n",
    "- Each fold acts as the testing set once, while the remaining **k-1 folds** are used for training.  \r\n",
    "- The modelâ€™s performance is **averaged across all folds** for a comprehensive evaluation.\r\n",
    "\r\n",
    "### **2. Stratified K-Fold Cross-Validation**  \r\n",
    "- Similar to K-Fold, but ensures **class distribution** in each fold matches the original dataset.  \r\n",
    "- Ideal for **imbalanced datasets**, ensuring fair evaluation of all classes.\r\n",
    "\r\n",
    "### **3. Leave-One-Out Cross-Validation (LOOCV)**  \r\n",
    "- Each data point is used as a **testing set once**, while the rest form the training set.  \r\n",
    "- Very detailed but **computationally expensive** for large datasets.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **When to Use Each Technique?**\r\n",
    "| Technique                | When to Use                                                |\r\n",
    "|--------------------------|-----------------------------------------------------------|\r\n",
    "| **K-Fold**               | General-purpose validation with balanced data.            |\r\n",
    "| **Stratified K-Fold**    | When dealing with **imbalanced datasets** (e.g., rare classes). |\r\n",
    "| **LOOCV**                | For small datasets where #KFold #StratifiedKFold #LOOCV #ModelEvaluation #Python\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd66370-470d-46d1-854e-f145d3edad6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f1fda-0ccf-450e-88d6-ab22d6674d0f",
   "metadata": {},
   "source": [
    "## Practical Implementation\n",
    "### Steps to Perform K-Fold Cross-Validation:\n",
    "#### 1. Import Required Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901d7926-05a6-45a0-925d-0e9635bf67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c78b9-0d47-4ac5-8c9b-49a438ead465",
   "metadata": {},
   "source": [
    "#### 2. Load and Prepare Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8670e9-f85e-4ccd-9f3c-d43924a2ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e38825-87f6-438f-af84-a54aba1a1664",
   "metadata": {},
   "source": [
    "#### 3. Choose a Model: Logistic regression or decision trees will be used for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2f009e-e57d-48ca-af49-aa9c364a8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "dt_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3d039-e35b-444f-ae78-79937e42e149",
   "metadata": {},
   "source": [
    "#### 4. Perform K-Fold Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b785d714-2d9f-46fa-b097-7c8b1253d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "Decision Tree Accuracy Scores: [1.         0.96666667 0.93333333 0.93333333 0.93333333]\n",
      "Mean Accuracy: 0.9533333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "log_reg_scores = cross_val_score(log_reg, X, y, cv=kfold, scoring='accuracy')\n",
    "print(\"Logistic Regression Accuracy Scores:\", log_reg_scores)\n",
    "print(\"Mean Accuracy:\", log_reg_scores.mean())\n",
    "\n",
    "dt_scores = cross_val_score(dt_model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(\"Decision Tree Accuracy Scores:\", dt_scores)\n",
    "print(\"Mean Accuracy:\", dt_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd9426-495f-4c12-b6bf-92bd272d2922",
   "metadata": {},
   "source": [
    "#### 5. Perform Stratified K-Fold Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa86ab2-fe85-4a13-9a12-7eb942a449b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Stratified K-Fold Accuracy: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
      "Mean Accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "log_reg_strat_scores = cross_val_score(log_reg, X, y, cv=skfold, scoring='accuracy')\n",
    "print(\"Logistic Regression with Stratified K-Fold Accuracy:\", log_reg_strat_scores)\n",
    "print(\"Mean Accuracy:\", log_reg_strat_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845ba0d-d076-48f2-b642-9d5643c7428d",
   "metadata": {},
   "source": [
    "#### 6. Interpretation of Results:\n",
    "\n",
    "- Each fold provides a performance score (e.g., accuracy).\n",
    "- The final evaluation is the average performance across all folds.\n",
    "- Standard deviation of scores indicates how consistent the model's performance is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc6103-9737-4e06-86ef-c0bc4f471708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
