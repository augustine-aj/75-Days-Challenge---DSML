{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958f99d6-b5dd-4182-985b-eb0eedd36d60",
   "metadata": {},
   "source": [
    "# Feature Engineering and Feature Selection\n",
    "\n",
    "Feature engineering and feature selection are crucial steps for building effective machine learning models. These processes enhance model performance by improving the quality and relevance of features.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Feature engineering involves creating or modifying features to extract meaningful information from raw data. It aims to enhance the predictive power of the model.\n",
    "\n",
    "### Steps in Feature Engineering:\n",
    "1. **Handling Missing Data**:\n",
    "   - Fill missing values using techniques like:\n",
    "     - Mean/median imputation.\n",
    "     - Forward/backward fill.\n",
    "   \n",
    "2. **Transforming Features**:\n",
    "   - Apply transformations such as:\n",
    "     - Scaling: Use `StandardScaler` or `MinMaxScaler` to normalize features.\n",
    "     - Encoding categorical variables: Apply one-hot or label encoding.\n",
    "     - Logarithmic transformations for skewed data.\n",
    "\n",
    "3. **Creating New Features**:\n",
    "   - Generate features by combining or splitting existing ones.\n",
    "     - Example: Create `total_purchase` from `quantity` and `price`.\n",
    "\n",
    "4. **Handling Outliers**:\n",
    "   - Remove or cap extreme values using statistical methods like:\n",
    "     - Z-scores.\n",
    "     - Interquartile range (IQR).\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "Feature selection identifies the most relevant features to reduce complexity, improve model performance, and minimize noise or overfitting.\n",
    "\n",
    "### Techniques for Feature Selection:\n",
    "1. **Filter Methods**:\n",
    "   - Rank features based on statistical relevance using:\n",
    "     - Chi-square test.\n",
    "     - ANOVA (Analysis of Variance).\n",
    "\n",
    "2. **Wrapper Methods**:\n",
    "   - Evaluate subsets of features and select the optimal combination.\n",
    "   - Example: Recursive Feature Elimination (RFE).\n",
    "\n",
    "3. **Embedded Methods**:\n",
    "   - Use algorithms with built-in feature importance measures, such as:\n",
    "     - Lasso Regression (L1 regularization).\n",
    "     - Decision Trees and Tree-based models.\n",
    "\n",
    "---\n",
    "\n",
    "Feature engineering and selection are iterative processes that require domain knowledge, exploratory data analysis, and experimentation to optimize model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bf595-5f48-4625-9220-a8ec48497526",
   "metadata": {},
   "source": [
    "## Implementation in Python\n",
    "#### 1. Using SelectKBest (Filter Method)\n",
    "SelectKBest selects the top k features based on statistical tests like ANOVA F-statistic or chi-square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7af90ed-a77a-43b7-8caa-a30fde9814fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      " [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected Features:\\n\", X_selected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c282e-7d5b-4ce5-84cb-e31a384450f2",
   "metadata": {},
   "source": [
    "#### 2. Using Recursive Feature Elimination (RFE)\n",
    "RFE recursively removes the least important features based on a model's weights (e.g., a Decision Tree or Logistic Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d632849-00a3-4936-a13e-fd44bb3149c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      " [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n",
      "Feature Ranking: [3 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=model, n_features_to_select=2)\n",
    "\n",
    "X_selected = rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected Features:\\n\", X_selected[:5])\n",
    "print(\"Feature Ranking:\", rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd00d5-7450-48a6-8522-5db798a58140",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Key Benefits\n",
    "- **Improved Model Accuracy:** By focusing on the most relevant features.\n",
    "- **Reduced Overfitting:** By eliminating noisy and redundant features.\n",
    "- **Faster Training Time:** By reducing the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abb9c5-784d-4902-9f68-710091eab51e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Feature engineering transforms raw data into meaningful features, while feature selection identifies the most impactful ones. Together, they ensure your machine learning models are both efficient and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4769b44-421e-4571-b6fb-bc592d2df289",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60a758-4db3-48c3-bb26-ffd67f0f1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
