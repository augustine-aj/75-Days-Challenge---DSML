{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d6d91-73f2-479b-9c8c-fb979f3ce211",
   "metadata": {},
   "source": [
    "# **Introduction to Deep Learning** ðŸŒŸ\n",
    "\n",
    "Deep learning is a powerful subfield of machine learning inspired by the structure and function of the human brain. It uses **artificial neural networks (ANNs)** to model and solve complex problems.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basics of Neural Networks**\n",
    "A neural network is designed to recognize patterns in data and mimics the way the human brain processes information.  \n",
    "\n",
    "### **Key Components:**\n",
    "- **Input Layer**: Receives raw data (e.g., images, text, numbers).\n",
    "- **Hidden Layers**: Perform intermediate computations using weights, biases, and activation functions.\n",
    "- **Output Layer**: Produces the final prediction or result.\n",
    "\n",
    "### **Learning Mechanism:**\n",
    "Neural networks adjust **weights** and **biases** during training to improve performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Structure of an Artificial Neural Network (ANN)**\n",
    "\n",
    "An ANN is built with the following elements:\n",
    "\n",
    "- **Nodes/Neurons**: Basic units that process inputs using a mathematical function.\n",
    "- **Weights**: Values that indicate the importance of connections between neurons.\n",
    "- **Biases**: Added values that improve the model's ability to fit data.\n",
    "- **Connections**: Links between neurons that transmit information.\n",
    "\n",
    "### **Example ANN Structure:**\n",
    "1. **Input Layer**: Accepts input data.\n",
    "2. **Hidden Layers**: Transform data using weights, biases, and activation functions.\n",
    "3. **Output Layer**: Produces the final output or prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Activation Functions**\n",
    "\n",
    "Activation functions introduce **non-linearity**, enabling the network to learn complex patterns.\n",
    "\n",
    "### **Common Activation Functions:**\n",
    "- **Sigmoid**: Outputs values between 0 and 1.  \n",
    "  [Example: Logistic Regression](https://upload.wikimedia.org/math/1/d/c/1dc9fa97e2e71c1b87b75f00098ef8c0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78ce51-5148-4095-ab0b-2f1862650c6d",
   "metadata": {},
   "source": [
    "# **Deep Learning: Forward Propagation & Backpropagation** ðŸ”„\n",
    "\n",
    "Understanding the flow of information and learning mechanisms in neural networks is crucial for building deep learning models. Let's explore these processes step-by-step.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Forward Propagation**\n",
    "\n",
    "Forward propagation calculates the output of the neural network by passing input data through its layers.\n",
    "\n",
    "### **Steps:**\n",
    "1. Multiply inputs by weights and add biases.\n",
    "2. Pass the result through an activation function.\n",
    "3. Repeat the process for all layers until reaching the output layer.\n",
    "\n",
    "### **Key Insight:**\n",
    "Each neuron applies a function \\( f(w \\cdot x + b) \\) to determine its output.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Backpropagation**\n",
    "\n",
    "Backpropagation is the learning process where the network updates its weights and biases to minimize errors.\n",
    "\n",
    "### **Steps:**\n",
    "1. Compute the loss (error) using a **loss function** like:\n",
    "   - Mean Squared Error (MSE)\n",
    "   - Cross-Entropy Loss\n",
    "2. Apply **gradient descent** to calculate weight updates based on the loss gradient.\n",
    "3. Adjust weights and biases to reduce the loss and improve accuracy.\n",
    "\n",
    "### **Why Backpropagation Matters:**\n",
    "- Helps the model learn from its mistakes.\n",
    "- Fine-tunes parameters to improve predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Concepts Recap**\n",
    "\n",
    "- **Forward Propagation**: Flows data through the network to produce outputs.\n",
    "- **Backpropagation**: Updates weights and biases to minimize errors.\n",
    "\n",
    "---\n",
    "\n",
    "## **Day 1 Summary** ðŸ§ \n",
    "- Learned the **building blocks of neural networks**.\n",
    "- Understood the process of **forward propagation** to calculate predictions.\n",
    "- Explored how neural networks **learn using backpropagation**.\n",
    "\n",
    "This foundational knowledge prepares you to implement simple neural networks and dive into advanced architectures like **Convolutional Neural Networks (CNNs)** and **Recurrent Neural Networks (RNNs)**.\n",
    "\n",
    "---\n",
    "\n",
    "Stay tuned for **Day 2**, where we dive deeper into activation functions and optimization algorithms! ðŸš€\n",
    "\n",
    "**#DeepLearning #NeuralNetworks #ForwardPropagation #Backpropagation #MachineLearning #AI #DataScience**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001095fd-1427-400d-b285-c46fa32ed13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
