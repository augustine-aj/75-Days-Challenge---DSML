{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e290e2-b22a-44d5-8b62-9007046e28b9",
   "metadata": {},
   "source": [
    "# Transfer Learning Basics - Explanation\n",
    "## What is Transfer Learning?\n",
    "`Transfer Learning` is a powerful technique in deep learning where a pre-trained model is reused on a new problem. Instead of training a model from scratch (which requires lots of data and computational resources), we take a model that has been trained on a large dataset (like ImageNet) and adapt it for our specific task.\n",
    "\n",
    "## Why Use Transfer Learning?\n",
    "- **Reduces Training Time:** Pre-trained models already contain learned features, so fewer resources are needed.\n",
    "- **Small Datasets:** Even with limited data, Transfer Learning works effectively because the model has generalized patterns from large datasets.\n",
    "- **Improved Performance:** Leveraging state-of-the-art architectures like VGG16, ResNet, or Inception allows for higher accuracy and better generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-Trained Models and Architectures\n",
    "- **VGG16 (Visual Geometry Group 16):**\n",
    "\n",
    "    - Consists of 16 layers (13 convolutional layers + 3 fully connected layers).\n",
    "    - Simple, uniform architecture with repeated 3x3 convolutional filters.\n",
    "    - **Strength:** Performs well for image classification tasks.\n",
    "    - **Limitations:** Computationally expensive due to its high number of parameters.\n",
    "- **ResNet (Residual Network):**\n",
    "\n",
    "    - Introduces skip connections (or residual connections), solving the `vanishing gradient` problem in deep networks.\n",
    "    - Allows networks to go extremely deep (e.g., ResNet-50, ResNet-101).\n",
    "    - **Strength:** Efficient, deeper, and more accurate.\n",
    "- **Inception:**\n",
    "\n",
    "    - Uses inception modules that apply multiple filter sizes (1x1, 3x3, 5x5) in parallel to capture information at multiple scales.\n",
    "    - Incorporates techniques like `bottleneck layers` for dimensionality reduction and `global average pooling` to reduce overfitting.\n",
    "    - **Strength:** Good accuracy with efficient computational performance.\n",
    "\n",
    "---\n",
    "\n",
    "## How Transfer Learning Works\n",
    "- **Feature Extraction:** Use a pre-trained model as a feature extractor. Freeze the lower layers (which contain general features) and train only the top layers for the new task.\n",
    "- **Fine-Tuning:** Slightly retrain some layers of the pre-trained model (typically the top layers) while keeping earlier layers fixed.\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications of Transfer Learning\n",
    "- **Image Classification:** Classify objects (e.g., cats vs. dogs) using pre-trained models like VGG16.\n",
    "- **Medical Imaging:** Diagnose diseases from images (e.g., X-rays) using models pre-trained on natural images.\n",
    "- **Object Detection:** Use architectures like Faster R-CNN for identifying and detecting objects in videos or images.\n",
    "- **Natural Language Processing:** Techniques like BERT or GPT-3 for text-based tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Example in Keras\n",
    "Load a pre-trained VGG16 model, freeze its lower layers, and train on a new task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3550b9d5-fde4-4ae8-96b2-0ea1a5812fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Loading a H5 file requires `h5py` to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten\n\u001b[1;32m----> 5\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m      8\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda new\\Lib\\site-packages\\keras\\src\\applications\\vgg16.py:224\u001b[0m, in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[0;32m    221\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         )\n\u001b[1;32m--> 224\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[1;32m~\\anaconda new\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda new\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:260\u001b[0m, in \u001b[0;36mload_weights\u001b[1;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m h5py:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a H5 file requires `h5py` to be installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "\u001b[1;31mImportError\u001b[0m: Loading a H5 file requires `h5py` to be installed."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead73dbb-0e2f-4f2f-a458-27d9009295df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ade73a-6044-40e4-bfb9-fa9632ba8b8f",
   "metadata": {},
   "source": [
    "##Key Takeaways\n",
    "- Transfer Learning leverages pre-trained models, saving time and improving performance.\n",
    "- Popular architectures like VGG16, ResNet, and Inception have specific strengths and are widely used.\n",
    "Transfer Learning is ideal for tasks with limited labeled data.\n",
    "Next, you'll explore how to implement these architectures on your custom dataset and compare results! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
