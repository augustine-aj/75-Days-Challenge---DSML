{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9e5214-a69c-4b8b-9bdd-7f38e5fdba74",
   "metadata": {},
   "source": [
    "# **Day 12: Visualizing CNN Predictions**\n",
    "\n",
    "Understanding why a Convolutional Neural Network (CNN) makes specific predictions is critical for both improving model performance and ensuring trust in AI systems. Visualization techniques like Grad-CAM can provide valuable insights into the inner workings of CNNs.\n",
    "\n",
    "---\n",
    "\n",
    "## **Theory**\n",
    "\n",
    "### **What is Grad-CAM (Gradient-weighted Class Activation Mapping)?**\n",
    "- Grad-CAM is a technique that visualizes which parts of an image contribute the most to a CNN's prediction.\n",
    "- It overlays a heatmap onto the image, highlighting the areas of interest.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Visualize Predictions?**\n",
    "1. **Interpretability**: Helps identify the features influencing the model's decision.\n",
    "2. **Debugging**: Reveals potential flaws in the dataset or biases in the model.\n",
    "3. **Trust and Transparency**: Essential for applications where explainability is critical, like healthcare or finance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Practical Implementation**\n",
    "\n",
    "### **Dataset**\n",
    "- Use a dataset such as **Cats vs. Dogs** or **CIFAR-10**.\n",
    "\n",
    "### **Steps to Visualize Predictions**\n",
    "1. **Step 1**: Load your trained CNN model and an image for prediction.\n",
    "2. **Step 2**: Compute gradients of the output class (prediction) concerning the feature map in the final convolutional layer.\n",
    "3. **Step 3**: Use these gradients to compute the importance of each neuron in the feature map.\n",
    "4. **Step 4**: Create a heatmap to highlight the most critical regions influencing the prediction.\n",
    "5. **Step 5**: Overlay the heatmap onto the original image.\n",
    "\n",
    "---\n",
    "\n",
    "### **Libraries to Use**\n",
    "- **TensorFlow/Keras**: For model creation and prediction.\n",
    "- **OpenCV, Matplotlib, or PIL**: For visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defbbaa-5149-4a18-abac-b6e422135aed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec6142-db4e-450c-b528-1540a4b8cc2e",
   "metadata": {},
   "source": [
    "## Example Code\n",
    "**Hereâ€™s a simplified Grad-CAM implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477295d-14bc-4361-90a3-4cce67ba2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b1647-e1c8-45e9-9bfa-a4428191d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "image_path = \"cat.jpg\"\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = tf.keras.applications.vgg16.preprocess_input(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a99e9e-1c36-4f26-8230-69fe28061fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99393c-64a5-4b2c-a4fe-51f79d9ed4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(\"block5_conv3\").output, model.output])\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img_array)\n",
    "    loss = predictions[:, predicted_class]\n",
    "grads = tape.gradient(loss, conv_outputs)\n",
    "weights = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "cam = tf.reduce_sum(weights * conv_outputs[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6df2ee-dd05-4888-a9fc-3fef74246632",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = np.maximum(cam, 0)  # ReLU\n",
    "cam = cam / cam.max()\n",
    "heatmap = np.uint8(255 * cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc8fae-8655-41fc-a93c-73f69e8c5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.expand_dims(heatmap, axis=-1)\n",
    "overlay = img_array[0] * 0.6 + heatmap * 0.4\n",
    "plt.imshow(np.uint8(overlay))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c7007-9b16-4634-a0ba-9b649ee9041c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2504e4-4bb9-42d4-924e-6d8ad60d6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Key Insights from Visualization\n",
    "- **Localizing Predictions:** Understand which parts of the image most strongly influenced the model.\n",
    "- Highlighting Dataset Issues: Spot inconsistencies, biases, or misleading data.\n",
    "- Improving Model Performance: Adjust hyperparameters, architecture, or data preprocessing based on findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
